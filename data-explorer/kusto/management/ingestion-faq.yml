### YamlMime:FAQ
metadata:
  title: Azure Data Explorer ingestion FAQ 
  description: "Get answers to common questions about Azure Data Explorer ingestion."
  ms.date: 10/21/2021
title: Common questions about Azure Data Explorer ingestion
summary: This article answers commonly asked questions about Azure Data Explorer ingestion.
sections: 
  - name: Batching and data latencies
    questions:
      - question: How does batching affect my data?
        answer: |
          The batching manager buffers and batches ingress data based on the ingestion settings in the [ingestion batching policy](batchingpolicy.md). The ingestion batching policy sets batch limits according to three limiting factors, whichever is first reached: time elapsed since batch creation, accumulated number of items (blobs), or total batch size. The default batching settings are 5 minutes / 1 GB / 1000 blobs, meaning there will be at least a 5 minute delay when queueing a sample data for ingestion.
      - question: Do I need to change the batching policy?
        answer: |
          If default settings for the [ingestion batching policy](batchingpolicy.md) do not suit your needs, you can try lowering the batching policy `time`. See also [ingestion best practices - optimizing for throughput](../api/netfx/kusto-ingest-best-practices.md#optimizing-for-throughput). You should also update settings when you scale up ingestion. When you change batching policy settings, it can take up to 5 minutes to take effect. 
      - question: What causes batching latency?
        answer: |
          Ingestion latency can result from the [ingestion batching policy](batchingpolicy.md) settings, or a data backlog buildup. To address this, adjust the [batching policy settings](batching-policy.md).
          Latencies that are part of the ingestion process can be [monitored](../../monitor-batching-ingestion.md).      
      - question: Where can I view batching latency metrics?
        answer: |
          To view ingestion latency metrics, see [monitoring ingestion latency](../../monitor-batching-ingestion.md#view-the-ingestion-latency). The metrics `Stage Latency` and `Discovery Latency` show latencies in the ingestion process, and reveal if there are any long latencies.
      - question: How can I shorten batching latencies? 
        answer: |
          You can [change settings in the batching policy](batchingpolicy.md#batching-latencies) to address issues that cause latencies such as data backlogs, inefficient batching, batching very large amounts of uncompressed data, or ingesting very small amounts of data. 
      - question: How is batching data size calculated? 
        answer: |
          The batching policy data size is set for uncompressed data. When ingesting compressed data, the [uncompressed data size is calculated](batchingpolicy.md#batch-data-size) from ingestion batching parameters, zip files metadata, or factor over the compressed file size.
      - question: How can I improve ingestion with SDK?
        answer: |
          When ingesting via SDK, you can use the ingestion [batching policy settings to improve performance](../../net-sdk-ingest-data.md). 
          Try incrementally decreasing the size of data ingested in the table or database batching policy down towards 250 MB and check if there is an improvement.
      - question: How can I tune Kusto Kafka Sink for better ingestion performance?
        answer: |
          [Kafka Sink](https://github.com/Azure/kafka-sink-azure-kusto/blob/master/README.md) users should [tune the connector](../../ingest-data-kafka.md) to work together with the [ingestion batching policy](batchingpolicy.md) by tuning batching time, size, and item number. 
